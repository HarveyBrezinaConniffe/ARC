{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n",
    "seed = 18\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "with os.scandir('test/') as entries:\n",
    "    for entry in entries:\n",
    "        names.append(\"test/\"+entry.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(name) as json_file:\n",
    "        data = json.load(json_file) \n",
    "        l = len(data['train'])\n",
    "        i = 0\n",
    "        for t in data['train']:\n",
    "            i += 1\n",
    "            \n",
    "            cX = np.zeros((30, 30, channels))\n",
    "            cY = np.zeros((30, 30, channels))\n",
    "            \n",
    "            cin = np.array(t['input'])\n",
    "            cinr = np.full((30, 30), -1)\n",
    "            cinr[:cin.shape[0], :cin.shape[1]] = cin\n",
    "            cX[:, :, 0] = cinr\n",
    "            #! Clone?\n",
    "            cX[:, :, 1] = cinr\n",
    "            \n",
    "            cout = np.array(t['output'])\n",
    "            coutr = np.full((30, 30), -1)\n",
    "            coutr[:cout.shape[0], :cout.shape[1]] = cout\n",
    "            cY[:, :, 0] = coutr\n",
    "            #! Clone?\n",
    "            cY[:, :, 1] = coutr\n",
    "            X.append(cX)\n",
    "            Y.append(cY)\n",
    "            \n",
    "        for t in data['test']:\n",
    "            i += 1\n",
    "            \n",
    "            cX = np.zeros((30, 30, channels))\n",
    "            cY = np.zeros((30, 30, channels))\n",
    "            \n",
    "            cin = np.array(t['input'])\n",
    "            cinr = np.full((30, 30), -1)\n",
    "            cinr[:cin.shape[0], :cin.shape[1]] = cin\n",
    "            cX[:, :, 0] = cinr\n",
    "            #! Clone?\n",
    "            cX[:, :, 1] = cinr\n",
    "            \n",
    "            X.append(cX)\n",
    "\n",
    "    return [np.array(X), np.array(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def plot(inp):\n",
    "        plt.imshow(inp[:, :, 0].reshape(30, 30))\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    def plotf(inp):\n",
    "        plt.imshow(inp)\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(x, y):\n",
    "    return tf.reduce_mean(tf.square(x[:, :, :, 0]-y[:, :, :, 0]))\n",
    "\n",
    "def train(model, ctask, epochs, iterations, channels, verbose=False, validate=False, wholetask=None):\n",
    "    trainer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    origx = ctask[0]\n",
    "    x = origx.copy()\n",
    "    y = ctask[1]\n",
    "\n",
    "    mask = np.zeros((x.shape[0], 30, 30, channels))\n",
    "    mask[:, :, :, 1] = 1\n",
    "    xl2 = origx*mask\n",
    "\n",
    "    for k in range(epochs):\n",
    "        x = origx.copy()\n",
    "        with tf.GradientTape() as g:\n",
    "            for i in tf.range(iterations):\n",
    "                dx = model(x)\n",
    "                x = x+(dx*1)\n",
    "                x = x*(1-mask)+xl2\n",
    "            loss = loss_f(x, y)\n",
    "            grads = g.gradient(loss, model.weights)\n",
    "            #grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
    "            trainer.apply_gradients(zip(grads, model.weights))\n",
    "\n",
    "    return model\n",
    "\n",
    "def generate(model, cin, channels, iterations):\n",
    "    mask = np.zeros((cin.shape[0], 30, 30, channels))\n",
    "    mask[:, :, :, 1] = 1\n",
    "    xl2 = cin*mask\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        dx = model(cin)\n",
    "        cin = cin+(dx*1)\n",
    "        cin = cin*(1-mask)+xl2\n",
    "        if i%10 == 0:\n",
    "            pass\n",
    "            #toprint = cin.numpy()[0]\n",
    "            #plot(toprint)\n",
    "    \n",
    "    toprint = cin.numpy()\n",
    "    return toprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred\n",
    "\n",
    "def solve(taskname):\n",
    "    models = []\n",
    "    modelcount = 5\n",
    "\n",
    "    ntasks = 5\n",
    "    channels = 18\n",
    "    filters = 3\n",
    "    perceptionsize = 3\n",
    "    neurons = 128\n",
    "    epochs = 200\n",
    "    iterations = 25\n",
    "\n",
    "    ctask = load(taskname)\n",
    "    cin = [ctask[0][0:-1], ctask[1][0:]]\n",
    "    ctest = [ctask[0][-1]]\n",
    "    \n",
    "    if debug:\n",
    "        plot(ctask[0][0])\n",
    "        plot(ctask[1][0])\n",
    "        plot(ctest[0][0])\n",
    "\n",
    "    outs = []\n",
    "\n",
    "    for i in range(modelcount):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D((perceptionsize, perceptionsize), input_shape=(30, 30, channels), strides=[1, 1], padding=\"same\", depth_multiplier=filters, activation=\"relu\"),\n",
    "            tf.keras.layers.Conv2D(neurons, 1, activation=\"relu\"),\n",
    "            tf.keras.layers.Conv2D(channels, 1, activation=None, kernel_initializer=tf.zeros_initializer)\n",
    "        ])\n",
    "        model = train(model, cin, epochs, iterations, channels, False, False, ctask)\n",
    "        out = generate(model, np.array([ctest[0]]), channels, iterations)[0]\n",
    "        outs.append(out)\n",
    "        plot(out)\n",
    "\n",
    "    outs = np.array(outs)\n",
    "    fout = np.clip(np.round(np.mean(outs, axis=0)), -1, 9)\n",
    "    if debug:\n",
    "        plot(fout)\n",
    "\n",
    "    final = fout[:, :, 0]\n",
    "    x = np.argmin(final[0, :])\n",
    "    y = np.argmin(final[:, 0])\n",
    "    cropped = final[:y, :x]\n",
    "    finalout = flattener(cropped.astype(int).tolist())\n",
    "    if debug:\n",
    "        plotf(cropped)\n",
    "        print(finalout)\n",
    "    return finalout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=',')\n",
    "    writer.writerow(['output_id','output'])\n",
    "    for name in names:\n",
    "        writer.writerow([name, solve(name)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
