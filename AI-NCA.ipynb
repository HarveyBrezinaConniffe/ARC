{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up data loading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n",
    "seed = 18\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "with os.scandir('training/') as entries:\n",
    "    for entry in entries:\n",
    "        names.append(\"training/\"+entry.name)\n",
    "\n",
    "with os.scandir('test/') as entries:\n",
    "    for entry in entries:\n",
    "        names.append(\"test/\"+entry.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(name) as json_file:\n",
    "        data = json.load(json_file) \n",
    "        l = len(data['train'])\n",
    "        i = 0\n",
    "        for t in data['train']:\n",
    "            i += 1\n",
    "            \n",
    "            cX = np.zeros((30, 30, channels))\n",
    "            cY = np.zeros((30, 30, channels))\n",
    "            \n",
    "            cin = np.array(t['input'])\n",
    "            cinr = np.full((30, 30), -1)\n",
    "            cinr[:cin.shape[0], :cin.shape[1]] = cin\n",
    "            cX[:, :, 0] = cinr\n",
    "            #! Clone?\n",
    "            cX[:, :, 1] = cinr\n",
    "            \n",
    "            cout = np.array(t['output'])\n",
    "            coutr = np.full((30, 30), -1)\n",
    "            coutr[:cout.shape[0], :cout.shape[1]] = cout\n",
    "            cY[:, :, 0] = coutr\n",
    "            #! Clone?\n",
    "            cY[:, :, 1] = coutr\n",
    "            \n",
    "            X.append(cX)\n",
    "            Y.append(cY)\n",
    "    return [np.array(X), np.array(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(inp):\n",
    "    plt.imshow(inp[:, :, 0].reshape(30, 30))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(x, y):\n",
    "    return tf.reduce_mean(tf.square(x[:, :, :, 0]-y[:, :, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model, ctask, epochs, iterations, channels, verbose=False):\n",
    "    trainer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    origx = ctask[0]\n",
    "    x = origx.copy()\n",
    "    y = ctask[1]\n",
    "\n",
    "    mask = np.zeros((x.shape[0], 30, 30, channels))\n",
    "    mask[:, :, :, 1] = 1\n",
    "    xl2 = origx*mask\n",
    "\n",
    "    for k in range(epochs):\n",
    "        with tf.GradientTape() as g:\n",
    "            for i in tf.range(iterations):\n",
    "                x = model(x)\n",
    "                x = x*(1-mask)+xl2\n",
    "            loss = loss_f(x, y)\n",
    "            grads = g.gradient(loss, model.weights)\n",
    "            grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
    "            trainer.apply_gradients(zip(grads, model.weights))\n",
    "        if k%5 == 0:\n",
    "            if verbose:\n",
    "                print(\"LOSS AT EPOCH \"+str(k)+\": \"+str(loss.numpy()))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, cin, channels, iterations):\n",
    "    mask = np.zeros((1, 30, 30, channels))\n",
    "    mask[:, :, :, 1] = 1\n",
    "    xl2 = cin*mask\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        cin = model(cin)\n",
    "        cin = cin*(1-mask)+xl2\n",
    "        if i%10 == 0:\n",
    "            pass\n",
    "            #toprint = cin.numpy()[0]\n",
    "            #plot(toprint)\n",
    "    \n",
    "    toprint = cin.numpy()[0]\n",
    "    return toprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testacc(generated, groundtruth):\n",
    "    generated = generated[:, :, 0]\n",
    "    groundtruth = groundtruth[:, :, 0]\n",
    "    same = (generated==groundtruth).astype(int)\n",
    "    mask = (groundtruth != -1).astype(int)\n",
    "    same *= mask\n",
    "    return np.mean(same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "def test(ntasks, channels, filters, perceptionsize, neurons, epochs, iterations, plotting):\n",
    "    tasks = random.sample(names, k=ntasks)\n",
    "    avgacc = 0\n",
    "    i = 0\n",
    "    for task in tasks:\n",
    "        i += 1\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D((perceptionsize, perceptionsize), input_shape=(30, 30, channels), strides=[1, 1], padding=\"same\", depth_multiplier=filters, activation=\"relu\"),\n",
    "            tf.keras.layers.Conv2D(neurons, 1, activation=\"relu\"),\n",
    "            tf.keras.layers.Conv2D(channels, 1, activation=None, kernel_initializer=tf.zeros_initializer)\n",
    "        ])\n",
    "        ctask = load(task)\n",
    "        cin = [ctask[0][0:-1], ctask[1][0:-1]]\n",
    "        ctest = [ctask[0][-1], ctask[1][-1]]\n",
    "        model = train(model, cin, epochs, iterations, channels, False)\n",
    "        generated = np.clip(np.round(generate(model, np.array([ctest[0]]), channels, iterations)), -1, 9)\n",
    "        groundtruth = ctest[1]\n",
    "        if plotting:\n",
    "            plot(generated)\n",
    "            plot(groundtruth)\n",
    "        acc = testacc(generated, groundtruth)\n",
    "        avgacc += acc\n",
    "        print(\"CURRENT ACCURACY \"+str((avgacc/i)*100))\n",
    "    avgacc /= ntasks\n",
    "    return avgacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntasks = 10\n",
    "channels = 40\n",
    "filters = 5\n",
    "perceptionsize = 3\n",
    "neurons = 128\n",
    "epochs = 200\n",
    "iterations = 100\n",
    "\n",
    "cacc = test(ntasks, channels, filters, perceptionsize, neurons, epochs, iterations, True)\n",
    "print(cacc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.DepthwiseConv2D((3, 3), input_shape=(30, 30, channels), strides=[1, 1], padding=\"same\", depth_multiplier=filters, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(128, 1, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(channels, 1, activation=None, kernel_initializer=tf.zeros_initializer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = 10\n",
    "\n",
    "ctask = load(names[current])\n",
    "plot(ctask[0][0])\n",
    "plot(ctask[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(np.clip(np.round(out), -1, 9))\n",
    "plot(ctask[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testacc(np.clip(np.round(out), -1, 9), ctask[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
